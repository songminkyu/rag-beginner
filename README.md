# ğŸš€ LLM RAG Learning Repository

**2025ë…„ ìµœì‹  LLM RAG ê¸°ìˆ  í•™ìŠµì„ ìœ„í•œ ì¢…í•© ì €ì¥ì†Œ**

[![Python Version](https://img.shields.io/badge/python-3.9%2B-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![LangChain](https://img.shields.io/badge/LangChain-0.2%2B-orange.svg)](https://langchain.com)
[![LlamaIndex](https://img.shields.io/badge/LlamaIndex-0.12%2B-purple.svg)](https://llamaindex.ai)
[![EXAONE](https://img.shields.io/badge/EXAONE-4.0-red.svg)](https://huggingface.co/LGAI-EXAONE)

## ğŸ“– ê°œìš”

ì´ ì €ì¥ì†ŒëŠ” **Retrieval-Augmented Generation (RAG)** ê¸°ìˆ ì„ ì²´ê³„ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ ì¢…í•© í•™ìŠµ í”Œë«í¼ì…ë‹ˆë‹¤. 2025ë…„ ìµœì‹  ê¸°ìˆ  ìŠ¤íƒì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, íŠ¹íˆ **í•œêµ­ì–´ ì²˜ë¦¬ì— ìµœì í™”ëœ EXAONE 4.0 ëª¨ë¸**ì„ ì§€ì›í•©ë‹ˆë‹¤.

### âœ¨ ì£¼ìš” íŠ¹ì§•

- ğŸ”¥ **2025ë…„ ìµœì‹  ê¸°ìˆ **: LangChain 0.2+, LlamaIndex 0.12+, Gradio 4.0+ 
- ğŸ‡°ğŸ‡· **í•œêµ­ì–´ íŠ¹í™”**: EXAONE 4.0 ëª¨ë¸ê³¼ í•œêµ­ì–´ ë¬¸ì„œ ì²˜ë¦¬ ìµœì í™”
- ğŸ› ï¸ **ë‹¤ì–‘í•œ LLM ì§€ì›**: OpenAI GPT-4, Claude-3.5, ë¡œì»¬ EXAONE ëª¨ë¸
- ğŸ“š **ì²´ê³„ì  í•™ìŠµ**: ê¸°ì´ˆë¶€í„° ê³ ê¸‰ê¹Œì§€ 6ë‹¨ê³„ íŠœí† ë¦¬ì–¼
- ğŸ¯ **ì‹¤ë¬´ ì¤‘ì‹¬**: 4ê°€ì§€ ì‹¤ì œ í”„ë¡œì íŠ¸ ì˜ˆì œ
- ğŸ“Š **í¬ê´„ì  í‰ê°€**: RAGAS, BLEU, BERTScore ë“± ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì €ì¥ì†Œ í´ë¡  ë° ì„¤ì¹˜

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/your-username/llm-rag-learning.git
cd llm-rag-learning

# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
pip install -e .
```

### 2. í™˜ê²½ ì„¤ì •

```bash
# í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ìƒì„±
cp .env.example .env

# .env íŒŒì¼ì—ì„œ API í‚¤ ì„¤ì •
# OPENAI_API_KEY=your-openai-key
# ANTHROPIC_API_KEY=your-claude-key
```

### 3. EXAONE ë¡œì»¬ ëª¨ë¸ ì„¤ì • (ì„ íƒì‚¬í•­)

```bash
# Ollama ë° EXAONE ëª¨ë¸ ì„¤ì •
chmod +x scripts/setup_ollama.sh
./scripts/setup_ollama.sh
```

### 4. ì²« ë²ˆì§¸ RAG ì‹¤í–‰

```bash
# Hello RAG ì˜ˆì œ ì‹¤í–‰
python tutorials/01_getting_started/hello_rag.py
```

## ğŸ“ ì €ì¥ì†Œ êµ¬ì¡°

```
llm-rag-learning/
â”œâ”€â”€ ğŸ”§ core/                    # í•µì‹¬ ê¸°ëŠ¥ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ llm_providers/          # LLM ì œê³µì (OpenAI, Claude, EXAONE)
â”‚   â”œâ”€â”€ data_processing/        # ë°ì´í„° ì²˜ë¦¬ ë° ì„ë² ë”©
â”‚   â”œâ”€â”€ retrieval/              # ê²€ìƒ‰ ì—”ì§„
â”‚   â””â”€â”€ evaluation/             # í‰ê°€ ì‹œìŠ¤í…œ
â”œâ”€â”€ ğŸ“ tutorials/               # ë‹¨ê³„ë³„ í•™ìŠµ íŠœí† ë¦¬ì–¼
â”‚   â”œâ”€â”€ 01_getting_started/     # ì‹œì‘í•˜ê¸°
â”‚   â”œâ”€â”€ 02_data_preparation/    # ë°ì´í„° ì¤€ë¹„
â”‚   â”œâ”€â”€ 03_basic_rag/          # ê¸°ë³¸ RAG
â”‚   â”œâ”€â”€ 04_advanced_rag/       # ê³ ê¸‰ RAG
â”‚   â”œâ”€â”€ 05_local_models/       # ë¡œì»¬ ëª¨ë¸
â”‚   â””â”€â”€ 06_production_ready/   # í”„ë¡œë•ì…˜ ì¤€ë¹„
â”œâ”€â”€ ğŸ—ï¸ frameworks/             # í”„ë ˆì„ì›Œí¬ë³„ êµ¬í˜„
â”‚   â”œâ”€â”€ langchain_examples/     # LangChain ì˜ˆì œ
â”‚   â””â”€â”€ llamaindex_examples/    # LlamaIndex ì˜ˆì œ
â”œâ”€â”€ ğŸš€ projects/               # ì‹¤ìŠµ í”„ë¡œì íŠ¸
â”‚   â”œâ”€â”€ chatbot/               # ì±—ë´‡ í”„ë¡œì íŠ¸
â”‚   â”œâ”€â”€ document_qa/           # ë¬¸ì„œ Q&A
â”‚   â”œâ”€â”€ knowledge_base/        # ì§€ì‹ë² ì´ìŠ¤
â”‚   â””â”€â”€ multi_agent_rag/       # ë©€í‹° ì—ì´ì „íŠ¸ RAG
â””â”€â”€ ğŸ“Š data/                   # ìƒ˜í”Œ ë°ì´í„° ë° ë²¡í„° ìŠ¤í† ì–´
```

## ğŸ“ í•™ìŠµ ë¡œë“œë§µ

### ğŸ“š ë‹¨ê³„ë³„ íŠœí† ë¦¬ì–¼

| ë‹¨ê³„ | ë‚´ìš© | ì˜ˆìƒ ì‹œê°„ | ë‚œì´ë„ |
|------|------|----------|--------|
| **1ë‹¨ê³„** | [ì‹œì‘í•˜ê¸°](tutorials/01_getting_started/) | 30ë¶„ | â­ |
| **2ë‹¨ê³„** | [ë°ì´í„° ì¤€ë¹„](tutorials/02_data_preparation/) | 1ì‹œê°„ | â­â­ |
| **3ë‹¨ê³„** | [ê¸°ë³¸ RAG](tutorials/03_basic_rag/) | 2ì‹œê°„ | â­â­ |
| **4ë‹¨ê³„** | [ê³ ê¸‰ RAG](tutorials/04_advanced_rag/) | 3ì‹œê°„ | â­â­â­ |
| **5ë‹¨ê³„** | [ë¡œì»¬ ëª¨ë¸](tutorials/05_local_models/) | 2ì‹œê°„ | â­â­â­ |
| **6ë‹¨ê³„** | [í”„ë¡œë•ì…˜](tutorials/06_production_ready/) | 4ì‹œê°„ | â­â­â­â­ |

### ğŸ—ï¸ ì‹¤ìŠµ í”„ë¡œì íŠ¸

1. **ğŸ’¬ RAG ì±—ë´‡**: Gradio ê¸°ë°˜ ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤
2. **ğŸ“„ ë¬¸ì„œ Q&A**: PDF/DOCX ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ
3. **ğŸ§  ì§€ì‹ë² ì´ìŠ¤**: ê¸°ì—… ë‚´ë¶€ ì§€ì‹ ê´€ë¦¬ ì‹œìŠ¤í…œ
4. **ğŸ¤– ë©€í‹° ì—ì´ì „íŠ¸**: í˜‘ì—…í•˜ëŠ” AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ

## ğŸ› ï¸ ì§€ì› ê¸°ìˆ 

### ğŸ¤– LLM ì œê³µì

| ì œê³µì | ëª¨ë¸ | íŠ¹ì§• |
|--------|------|------|
| **OpenAI** | GPT-4o, GPT-4 Turbo | ë†’ì€ ì„±ëŠ¥, ë‹¤ì–‘í•œ ê¸°ëŠ¥ |
| **Anthropic** | Claude-3.5 Sonnet | ì•ˆì „ì„±, ê¸´ ì»¨í…ìŠ¤íŠ¸ |
| **LG AI** | EXAONE 4.0 (32B/7.8B/2.4B) | í•œêµ­ì–´ íŠ¹í™”, ë¡œì»¬ ì‹¤í–‰ |

### ğŸ“Š ë²¡í„° ìŠ¤í† ì–´

- **ChromaDB**: ë¡œì»¬ ê°œë°œìš©
- **FAISS**: ê³ ì„±ëŠ¥ ê²€ìƒ‰
- **Pinecone**: í´ë¼ìš°ë“œ ë²¡í„° DB

### ğŸ”§ í”„ë ˆì„ì›Œí¬

- **LangChain**: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì™€ ì—ì´ì „íŠ¸
- **LlamaIndex**: íš¨ìœ¨ì ì¸ ë°ì´í„° ì¸ë±ì‹±
- **Gradio**: í˜„ëŒ€ì ì¸ ì›¹ ì¸í„°í˜ì´ìŠ¤

## ğŸ’¡ ì‚¬ìš© ì˜ˆì œ

### ê¸°ë³¸ RAG ì‹œìŠ¤í…œ

```python
from core.llm_providers.local_provider import LocalLLMProvider
from tutorials.hello_rag import SimpleRAG

# EXAONE ëª¨ë¸ë¡œ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
rag = SimpleRAG("local")

# ë¬¸ì„œ ì¶”ê°€
documents = [
    "ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.",
    "ë¨¸ì‹ ëŸ¬ë‹ì€ AIì˜ í•œ ë¶„ì•¼ë¡œ ë°ì´í„°ë¡œë¶€í„° í•™ìŠµí•©ë‹ˆë‹¤."
]
rag.add_documents(documents)

# ì§ˆë¬¸í•˜ê¸°
result = rag.query("ì¸ê³µì§€ëŠ¥ì´ ë¬´ì—‡ì¸ê°€ìš”?")
print(f"ë‹µë³€: {result['answer']}")
```

### LangChain ê¸°ë°˜ ê³ ê¸‰ RAG

```python
from langchain.chains import RetrievalQA
from frameworks.langchain_examples.advanced_rag import ConversationalRAG

# ëŒ€í™”í˜• RAG ì‹œìŠ¤í…œ
conv_rag = ConversationalRAG(
    llm_provider="local",
    vector_store="chroma"
)

# ì—°ì† ëŒ€í™”
response1 = conv_rag.chat("RAGê°€ ë¬´ì—‡ì¸ê°€ìš”?")
response2 = conv_rag.chat("ê·¸ëŸ¼ ì–´ë–¤ ì¥ì ì´ ìˆë‚˜ìš”?")  # ì´ì „ ëŒ€í™” ê¸°ì–µ
```

## ğŸ”§ ê³ ê¸‰ ê¸°ëŠ¥

### ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
- ì˜ë¯¸ì  ê²€ìƒ‰ + í‚¤ì›Œë“œ ê²€ìƒ‰
- ì¬ìˆœìœ„ ë§¤ê¸°ê¸° (Reranking)
- ì¿¼ë¦¬ í™•ì¥ ë° ê°œì„ 

### ğŸ§  ë©”ëª¨ë¦¬ ê´€ë¦¬
- ëŒ€í™” íˆìŠ¤í† ë¦¬ ìœ ì§€
- ì»¨í…ìŠ¤íŠ¸ ì••ì¶•
- ë™ì  ë©”ëª¨ë¦¬ í• ë‹¹

### ğŸ“Š ì„±ëŠ¥ ìµœì í™”
- ë°°ì¹˜ ì²˜ë¦¬
- ìºì‹± ì‹œìŠ¤í…œ
- GPU ê°€ì†

### ğŸ” í‰ê°€ ì‹œìŠ¤í…œ
```python
from core.evaluation import RAGEvaluator

evaluator = RAGEvaluator()
results = evaluator.evaluate(
    questions=test_questions,
    answers=generated_answers,
    ground_truth=expected_answers,
    metrics=["ragas", "bleu", "bertscore"]
)
```

## ğŸŒŸ EXAONE 4.0 íŠ¹ë³„ ê¸°ëŠ¥

### ğŸ‡°ğŸ‡· í•œêµ­ì–´ ìµœì í™”
- í•œêµ­ì–´ ë¬¸ì„œ ì²˜ë¦¬ì— íŠ¹í™”
- í•œêµ­ ë¬¸í™” ì»¨í…ìŠ¤íŠ¸ ì´í•´
- í•œê¸€ í† í¬ë‚˜ì´ì € ì§€ì›

### ğŸ§  ì¶”ë¡  ëª¨ë“œ
```python
# EXAONE Deep ëª¨ë¸ì˜ ë‹¨ê³„ë³„ ì¶”ë¡ 
prompt = "<thought>\nìˆ˜í•™ ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ í’€ì–´ë³´ê² ìŠµë‹ˆë‹¤.\n</thought>\n\n2x + 5 = 15ë¥¼ í’€ì–´ì£¼ì„¸ìš”."
response = exaone_provider.generate(prompt)
```

### âš¡ ì„±ëŠ¥ ìµœì í™”
- Hybrid Attention êµ¬ì¡°
- QK-Reorder-Norm ê¸°ë²•
- íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ì‚¬ìš©

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ
| ëª¨ë¸ | í•œêµ­ì–´ ì„±ëŠ¥ | ì˜ì–´ ì„±ëŠ¥ | ì¶”ë¡  ì†ë„ | ë©”ëª¨ë¦¬ ì‚¬ìš© |
|------|-------------|-----------|-----------|-------------|
| EXAONE-32B | â­â­â­â­â­ | â­â­â­â­ | â­â­ | 32GB |
| EXAONE-7.8B | â­â­â­â­ | â­â­â­ | â­â­â­ | 8GB |
| GPT-4 | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | API |
| Claude-3.5 | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | API |

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangChain Documentation](https://python.langchain.com/)
- [LlamaIndex Documentation](https://docs.llamaindex.ai/)
- [EXAONE Model Card](https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B)
- [Ollama Documentation](https://ollama.ai/)

### ìœ ìš©í•œ ë§í¬
- [RAG ë…¼ë¬¸ ëª¨ìŒ](docs/references.md)
- [í•œêµ­ì–´ NLP ë¦¬ì†ŒìŠ¤](docs/korean_nlp.md)
- [ì„±ëŠ¥ íŠœë‹ ê°€ì´ë“œ](docs/performance_tuning.md)
- [ë°°í¬ ê°€ì´ë“œ](docs/deployment.md)

## â“ FAQ

<details>
<summary><b>Q: EXAONE ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ GPUê°€ í•„ìš”í•œê°€ìš”?</b></summary>

A: í•„ìˆ˜ëŠ” ì•„ë‹ˆì§€ë§Œ ê¶Œì¥ë©ë‹ˆë‹¤. CPUì—ì„œë„ ì‹¤í–‰ ê°€ëŠ¥í•˜ì§€ë§Œ, GPUë¥¼ ì‚¬ìš©í•˜ë©´ í›¨ì”¬ ë¹ ë¥¸ ì¶”ë¡ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- EXAONE-2.4B: CPUë¡œë„ ì¶©ë¶„
- EXAONE-7.8B: GPU ê¶Œì¥
- EXAONE-32B: GPU í•„ìˆ˜
</details>

<details>
<summary><b>Q: ì–´ë–¤ ëª¨ë¸ë¶€í„° ì‹œì‘í•˜ëŠ” ê²ƒì´ ì¢‹ë‚˜ìš”?</b></summary>

A: í•™ìŠµ ëª©ì ì´ë¼ë©´ ë‹¤ìŒ ìˆœì„œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤:
1. OpenAI GPT-4 (APIê°€ ìˆë‹¤ë©´)
2. EXAONE-7.8B (ë¡œì»¬ í™˜ê²½)
3. EXAONE-32B (ê³ ì„±ëŠ¥ í•„ìš”ì‹œ)
</details>

<details>
<summary><b>Q: ìƒì—…ì  ìš©ë„ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œê°€ìš”?</b></summary>

A: MIT ë¼ì´ì„¼ìŠ¤ë¡œ ìƒì—…ì  ì‚¬ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¨, ê° LLM ëª¨ë¸ì˜ ë¼ì´ì„¼ìŠ¤ë¥¼ ë³„ë„ë¡œ í™•ì¸í•´ì£¼ì„¸ìš”.
</details>

## ğŸ“„ ë¼ì´ì„¼ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” [MIT License](LICENSE) í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

## ğŸ™ ê°ì‚¬ì˜ ë§

- [LangChain](https://github.com/langchain-ai/langchain) íŒ€
- [LlamaIndex](https://github.com/run-llama/llama_index) íŒ€  
- [LG AI Research](https://www.lgresearch.ai/) EXAONE íŒ€
- [Ollama](https://github.com/ollama/ollama) íŒ€

---

<div align="center">

**ğŸŒŸ Star this repository if you find it helpful! ğŸŒŸ**

Made with â¤ï¸ for the Korean AI Community

</div>