# OpenAI API Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4o
OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# Anthropic Claude API Configuration
ANTHROPIC_API_KEY=your-anthropic-api-key-here
CLAUDE_MODEL=claude-3-5-sonnet-20241022

# Local Model Configuration (Ollama)
OLLAMA_BASE_URL=http://localhost:11434
EXAONE_MODEL_NAME=exaone4:7.8b
# Available EXAONE models: exaone4:32b, exaone4:7.8b, exaone4:2.4b

# Embedding Configuration
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384
# For Korean embeddings: jhgan/ko-sroberta-multitask

# Vector Store Configuration
VECTOR_STORE=chromadb  # Options: chromadb, faiss, pinecone
CHROMADB_PATH=./data/vector_stores/chromadb
FAISS_INDEX_PATH=./data/vector_stores/faiss

# Pinecone Configuration (if using Pinecone)
PINECONE_API_KEY=your-pinecone-api-key-here
PINECONE_ENVIRONMENT=us-west1-gcp-free
PINECONE_INDEX_NAME=rag-index

# Text Processing Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_TOKENS=4000

# RAG Configuration
RETRIEVAL_K=5  # Number of retrieved documents
SIMILARITY_THRESHOLD=0.7

# Evaluation Configuration
ENABLE_EVALUATION=true
EVAL_DATASET_PATH=./data/datasets/qa_pairs.json

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=./logs/rag_system.log

# Performance Configuration
BATCH_SIZE=32
USE_GPU=false
DEVICE=cpu  # Options: cpu, cuda, mps (for Apple Silicon)

# API Server Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true

# Gradio Configuration
GRADIO_PORT=7860
GRADIO_SHARE=false

# Development Configuration
DEBUG=false
ENVIRONMENT=development  # Options: development, production