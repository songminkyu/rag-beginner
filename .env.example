# =============================================================================
# LLM RAG Learning Repository Environment Variables
# 2025년 최신 설정
# =============================================================================

# OpenAI API Configuration
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_ORG_ID=org-your-organization-id  # Optional
OPENAI_MODEL=gpt-4o  # Latest GPT-4 model
OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# Claude (Anthropic) API Configuration  
ANTHROPIC_API_KEY=sk-ant-api03-your-claude-api-key-here
CLAUDE_MODEL=claude-3-5-sonnet-20241022  # Latest Claude model
CLAUDE_MAX_TOKENS=8192

# Local Model Configuration (EXAONE via Hugging Face Transformers)
EXAONE_MODEL=LGAI-EXAONE/EXAONE-4.0-32B  # or EXAONE-4.0-1.2B for smaller model
LOCAL_EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
DEVICE=auto  # auto, cuda, cpu
TORCH_DTYPE=bfloat16  # bfloat16, float16, float32
LOW_CPU_MEM_USAGE=true

# Vector Store Configuration
VECTOR_STORE_TYPE=chroma  # Options: chroma, faiss, pinecone
VECTOR_STORE_PATH=./data/vector_stores/chromadb
VECTOR_DIMENSION=1536

# ChromaDB Configuration
CHROMA_HOST=localhost
CHROMA_PORT=8000
CHROMA_COLLECTION_NAME=rag_documents

# Pinecone Configuration (if using Pinecone)
PINECONE_API_KEY=your-pinecone-api-key
PINECONE_ENVIRONMENT=us-west1-gcp
PINECONE_INDEX_NAME=rag-index

# Hugging Face Configuration
HF_TOKEN=hf_your-huggingface-token-here
HF_HOME=./models/huggingface

# Data Processing Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_DOCUMENTS=1000
SUPPORTED_EXTENSIONS=.pdf,.docx,.txt,.md,.html

# Retrieval Configuration
RETRIEVAL_TOP_K=5
SIMILARITY_THRESHOLD=0.7
RERANK_TOP_K=3

# Generation Configuration
TEMPERATURE=0.1
MAX_TOKENS=2048
STREAMING=true

# Evaluation Configuration
EVAL_DATASET_PATH=./data/datasets/qa_pairs.json
EVAL_METRICS=ragas,bleu,rouge,bertscore
EVAL_OUTPUT_PATH=./results/evaluation

# Monitoring and Logging
LOG_LEVEL=INFO
LOG_FILE=./logs/rag_learning.log
WANDB_PROJECT=llm-rag-learning
WANDB_API_KEY=your-wandb-api-key

# Server Configuration
SERVER_HOST=0.0.0.0
SERVER_PORT=8000
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# Development Configuration
DEBUG=false
CACHE_ENABLED=true
CACHE_TTL=3600

# Korean Language Processing (for EXAONE)
KOREAN_TOKENIZER=mecab
KOREAN_STOPWORDS_PATH=./data/korean_stopwords.txt

# Performance Configuration
MAX_WORKERS=4
BATCH_SIZE=32
GPU_MEMORY_FRACTION=0.8

# Security Configuration
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60
API_KEY_REQUIRED=false